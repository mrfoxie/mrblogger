{"title":"Face Detection using OpenCV + Python (üêç)","uid":"6ac81b31a02c426e346f8f4e43c2d44c","slug":"Face-Detection","date":"2021-06-21T16:05:37.000Z","updated":"2025-01-10T03:40:13.640Z","comments":true,"path":"api/articles/Face-Detection.json","keywords":null,"cover":"https://i.ytimg.com/vi/t-MDoI7MuY0/maxresdefault.jpg","content":"<p><img src=\"https://i.ytimg.com/vi/t-MDoI7MuY0/maxresdefault.jpg\" alt=\"Face Detection\"></p>\n<h2 id=\"What-is-Face-Detection\"><a href=\"#What-is-Face-Detection\" class=\"headerlink\" title=\"What is Face Detection?\"></a>What is Face Detection?</h2><p>Face detection is AI-based computer technology that is used to extract and identify human faces from digital images. When integrated with <a href=\"https://recfaces.com/articles/what-is-biometrics\">biometric</a> security systems (particularly, facial recognition ones), this kind of technology is what makes it possible to monitor and track people in real-time. In applications that use facial tracking, analysis, and recognition, face detection typically works as the first step and has a significant impact on how sequential operations within the app will perform.</p>\n<p>Face detection helps with facial analysis by identifying the parts of a video or an image that should be focused on when determining gender, age, and emotions. Similarly, with facial recognition systems (which create ‚Äúfaceprint‚Äù maps of facial features), face detection data is included in the system‚Äôs algorithms. And why? Face detection helps determine which parts of the video or image are needed to produce a faceprint.</p>\n<h2 id=\"HOW-DOES-FACE-DETECTION-WORK\"><a href=\"#HOW-DOES-FACE-DETECTION-WORK\" class=\"headerlink\" title=\"HOW DOES FACE DETECTION WORK?\"></a>HOW DOES FACE DETECTION WORK?</h2><p>Face detection technology uses machine learning and algorithms in order to extract human faces from larger images; such images typically contain plenty of non-face objects, such as buildings, landscapes, and various body parts.</p>\n<p>Facial detection algorithms usually begin by seeking out human eyes, which are one of the easiest facial features to detect. Next, the algorithm might try to find the mouth, nose, eyebrows, and iris. After identifying these facial features, and the algorithm concludes that it has extracted a face, it then goes through additional tests to confirm that it is, indeed, a face.</p>\n<p>To make algorithms as accurate as possible, they must be trained with huge data sets that contain hundreds of thousands of images. Some of these images contain faces, while others do not. The training procedures help the algorithm‚Äôs ability to decide whether an image contains faces, and where those facial regions are located.</p>\n<p>Also, now would be a good time to give you definitions of the main types of algorithms ‚Äì ML, AI, and Deep Learning.</p>\n<ul>\n<li><strong>Machine Learning (ML)</strong>: ML algorithms use statistics to find patterns in huge amounts of data. This data can include words, numbers, images, clicks, and more. ML is the process behind many modern services ‚Äì voice assistants (Siri and Alexa), search engines (Google and Baidu), and recommendation systems (Spotify and Netflix);</li>\n<li><strong>Artificial Intelligence (AI)</strong>: If an ML solution is programmed to learn how to perform a task, rather than just simple performance, then it is AI. Systems that use AI demonstrate behaviors similar to human intelligence ‚Äì for instance, problem solving, planning, learning, perception, manipulation, and reasoning;</li>\n<li><strong>Deep Learning:</strong> This algorithm is a subset of machine learning, and it is what forms deep neural networks; essentially, machines are given a greater ability to find and amplify tiny patterns. Such networks have any layers of computational nodes that collaborate to sift through data and deliver predictions.</li>\n</ul>\n<p>Now, as for the exact technologies used to develop face detection applications; these include:</p>\n<ul>\n<li>OpenCV;</li>\n<li>Matlab;</li>\n<li>Tensorflow;</li>\n<li>Neural Networks.</li>\n</ul>\n<p>All of these follow almost the exact same procedure for face detection.</p>\n<h3 id=\"FACE-DETECTION-METHODS\"><a href=\"#FACE-DETECTION-METHODS\" class=\"headerlink\" title=\"FACE DETECTION METHODS\"></a>FACE DETECTION METHODS</h3><p>Three researchers from the University of California, David Kriegman, Ming-Hsuan Yang, and Narendra Ahuja, published a classification of facial detection methods. There are four classifiable categories, of which face detection algorithms can belong to 2+ groups. Let‚Äôs take a look at each category.</p>\n<h4 id=\"Feature-Based-Method\"><a href=\"#Feature-Based-Method\" class=\"headerlink\" title=\"Feature-Based Method\"></a>Feature-Based Method</h4><p>This method located faces by extracting structural features. First, an algorithm is trained as a classifier. Next, it is used to sort facial regions from non-facial regions. The general idea is to move past humans‚Äô instinctive knowledge of faces. When feature-based approaches tackle photos with many faces, they have a 94% success rate.</p>\n<p><strong>Summary:</strong> Features such as a person‚Äôs nose or eyes are used to detect a face.</p>\n<h4 id=\"Knowledge-Based-Method\"><a href=\"#Knowledge-Based-Method\" class=\"headerlink\" title=\"Knowledge-Based Method\"></a>Knowledge-Based Method</h4><p>A knowledge-based algorithm is dependent upon a set of rules, and it is built on human knowledge. For instance, ‚Äúrules‚Äù might include that a face should have eyes, a nose, and a mouth in certain positions relative to each other. However, this kind of method comes with one huge challenge: it is very difficult to build an appropriate rules set. If the rules are too general, there may be many false positives ‚Äì and, conversely, if the rules are too detailed, the system could generate many false negatives.</p>\n<p><strong>Summary:</strong> A face is determined based on whether it meets a set of rules made by a human.</p>\n<h4 id=\"Template-Matching-Method\"><a href=\"#Template-Matching-Method\" class=\"headerlink\" title=\"Template Matching Method\"></a>Template Matching Method</h4><p>With a template matching algorithm, parameterized or pre-defined templates are used to locate or detect faces ‚Äì the system measures the correlation between the input photos and the templates. For instance, the template may show that a human face is divided into nose, mouth, eyes, and face contour regions. Also, a facial model could be comprised of just edges and use the edge detection method ‚Äì implementation of this approach is easy, but it is insufficient for face detection.</p>\n<p><strong>Summary:</strong> Images are compared to standard face patterns that have been previously stored.</p>\n<h4 id=\"Appearance-Based-Method\"><a href=\"#Appearance-Based-Method\" class=\"headerlink\" title=\"Appearance-Based Method\"></a>Appearance-Based Method</h4><p>An appearance-based algorithm uses a set of training images to ‚Äúlearn‚Äù what a face should look like. In general, this method relies on machine learning and statistical analysis to determine relevant facial characteristics. An appearance-based approach is generally considered to be stronger than the previously mentioned methods.</p>\n<p><strong>Summary:</strong> Statistical analysis and machine learning are combined to find a face image‚Äôs characteristics.</p>\n<h3 id=\"FACE-DETECTION-TECHNIQUES\"><a href=\"#FACE-DETECTION-TECHNIQUES\" class=\"headerlink\" title=\"FACE DETECTION TECHNIQUES\"></a>FACE DETECTION TECHNIQUES</h3><p>Some of the more specific facial detection techniques include:</p>\n<ol>\n<li>Removing the background. Let‚Äôs say an image has a pre-defined, static background or a plain, single-color background ‚Äì removing it can help determine the face‚Äôs boundaries;</li>\n<li>With color images, the color of the skin can sometimes be used to find faces;</li>\n<li>Motion can be used to detect faces. In a real-time video, a person‚Äôs face is nearly always in motion. However, a drawback of this technique is that a face could be confused with other moving objects.</li>\n</ol>\n<p>When the aforementioned strategies are combined, they can create a comprehensive face detection approach.</p>\n<h2 id=\"WHAT-ARE-THE-CHALLENGES-IN-FACE-DETECTION\"><a href=\"#WHAT-ARE-THE-CHALLENGES-IN-FACE-DETECTION\" class=\"headerlink\" title=\"WHAT ARE THE CHALLENGES IN FACE DETECTION?\"></a>WHAT ARE THE CHALLENGES IN FACE DETECTION?</h2><p>Researchers Ashu Kumar, Amandeep Kaur, and Munish Kumar published a <a href=\"https://www.researchgate.net/publication/326667118_Face_Detection_Techniques_A_Review\">review of face detection techniques</a>, which included a detailed explanation of the challenges that facial detection faces. To sum up their findings, the challenges in face detection include:</p>\n<ul>\n<li>Odd expressions. A human face might have an odd expression, making it difficult for facial detection algorithms to identify it as a face;</li>\n<li>Face occlusion. If a face is hidden by hair, a hat, a hand, glasses, or a scarf, it may result in a false negative;</li>\n<li>Illuminations. An image might not have uniform lighting effects; part of the image may be overexposed, while another part is very dark. Again, this can contribute to false negatives;</li>\n<li>Complex background. When lots of objects are present in an image, face detection‚Äôs accuracy is reduced;</li>\n<li>Too many faces. If there is a large number of human faces in an image, face detection software may have a hard time distinguishing between some of them;</li>\n<li>Low resolution. If an image‚Äôs resolution is poor, it is more difficult to detect faces;</li>\n<li>Skin color. If somebody‚Äôs skin color falls outside of the gradient that is recognized by the algorithm,<br>their face might not be detected.</li>\n</ul>\n<h2 id=\"HOW-DOES-FACE-DETECTION-WORK-WITH-DEEP-LEARNING\"><a href=\"#HOW-DOES-FACE-DETECTION-WORK-WITH-DEEP-LEARNING\" class=\"headerlink\" title=\"HOW DOES FACE DETECTION WORK WITH DEEP LEARNING?\"></a>HOW DOES FACE DETECTION WORK WITH DEEP LEARNING?</h2><p>As we mentioned earlier, deep learning is a subset of machine learning in which large neural networks process huge amounts of data and make complex predictions. So how does deep learning factor into face detection? Well, multiple <a href=\"https://arxiv.org/abs/1502.02766\">deep learning methods</a> have been developed specifically for facial detection.</p>\n<p>One of the most popular deep learning approaches is the Multi-Task Cascaded Convolutional Neural Network ‚Äì or, MTCNN. This approach is popular because it achieved cutting-edge results (for the time) on a variety of benchmark datasets ‚Äì plus, it is able to use landmark detection to recognize the eyes, mouth, and other facial features.</p>\n<p>MTCNN uses a cascade structure that contains three networks: P-net, R-Net, and O-Net. The image is first rescaled to different sizes (or an image period). P-Net proposes facial regions, R-Net filters the bounding boxes, and O-Net proposes facial landmarks.</p>\n<h2 id=\"WHY-IS-FACE-DETECTION-IMPORTANT-TODAY\"><a href=\"#WHY-IS-FACE-DETECTION-IMPORTANT-TODAY\" class=\"headerlink\" title=\"WHY IS FACE DETECTION IMPORTANT TODAY?\"></a>WHY IS FACE DETECTION IMPORTANT TODAY?</h2><p>Face detection is the initial step in face analysis, face tracking, and, most importantly, face recognition. The latter industry is growing by leaps and bounds, and is applied to device unlocking, banking, hospitality, law enforcement, building security, and more. Face detection is necessary for facial recognition algorithms to know which parts of an image must be used to generate faceprints.</p>\n<h2 id=\"FACE-DETECTION-VS-FACE-RECOGNITION-WHAT‚ÄôS-THE-DIFFERENCE\"><a href=\"#FACE-DETECTION-VS-FACE-RECOGNITION-WHAT‚ÄôS-THE-DIFFERENCE\" class=\"headerlink\" title=\"FACE DETECTION VS. FACE RECOGNITION: WHAT‚ÄôS THE DIFFERENCE?\"></a>FACE DETECTION VS. FACE RECOGNITION: WHAT‚ÄôS THE DIFFERENCE?</h2><p>Facial recognition is merely one application of face detection. The former is used for biometric verification and device unlocking, whereas the latter can also be applied to facial analysis and tracking. For a more comprehensive look at face recognition, check out our <a href=\"https://recfaces.com/articles/types-of-biometrics\">Types of Biometrics guide.</a></p>\n<h2 id=\"ADVANTAGES-AND-DISADVANTAGES-OF-FACE-DETECTION-SYSTEMS\"><a href=\"#ADVANTAGES-AND-DISADVANTAGES-OF-FACE-DETECTION-SYSTEMS\" class=\"headerlink\" title=\"ADVANTAGES AND DISADVANTAGES OF FACE DETECTION SYSTEMS\"></a>ADVANTAGES AND DISADVANTAGES OF FACE DETECTION SYSTEMS</h2><p>While face detection systems can be powerful, they are by no means foolproof, as demonstrated by our list of challenges. Let‚Äôs take a look at the advantages and disadvantages that face detection systems can bring.</p>\n<h3 id=\"ADVANTAGES-OF-FACE-DETECTION\"><a href=\"#ADVANTAGES-OF-FACE-DETECTION\" class=\"headerlink\" title=\"ADVANTAGES OF FACE DETECTION\"></a>ADVANTAGES OF FACE DETECTION</h3><ol>\n<li>Better security. Face detection augments surveillance tactics and forms the basis of the identification process of terrorists and criminals;</li>\n<li>Easy to integrate. Most face detection solutions are compatible with security software;</li>\n<li>Automated identification. Face detection lets facial identification be automated, thus increasing efficiency alongside a heightened rate of accuracy.</li>\n</ol>\n<h3 id=\"DISADVANTAGES-OF-FACE-DETECTION\"><a href=\"#DISADVANTAGES-OF-FACE-DETECTION\" class=\"headerlink\" title=\"DISADVANTAGES OF FACE DETECTION\"></a>DISADVANTAGES OF FACE DETECTION</h3><ol>\n<li>Huge storage requirements. Machine learning technology requires powerful data storage;</li>\n<li>Detection can be vulnerable. We‚Äôve outlined the way in which facial detection can be thrown off;</li>\n<li>Potential privacy issues. There is disagreement on whether face detection is compatible with human privacy rights.</li>\n</ol>\n<h3 id=\"PROS-AND-CONS-TABLE-SUMMARY\"><a href=\"#PROS-AND-CONS-TABLE-SUMMARY\" class=\"headerlink\" title=\"PROS AND CONS TABLE SUMMARY\"></a>PROS AND CONS TABLE SUMMARY</h3><table>\n<thead>\n<tr>\n<th>Advantages of Face Detection</th>\n<th>Disadvantages of Face Detection</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Better security</td>\n<td>Huge storage requirements</td>\n</tr>\n<tr>\n<td>Easy to integrate</td>\n<td>Vulnerable detection</td>\n</tr>\n<tr>\n<td>Automated identification</td>\n<td>Potential privacy issues</td>\n</tr>\n</tbody></table>\n<h2 id=\"HOW-FACE-DETECTION-ALGORITHMS-ARE-USED\"><a href=\"#HOW-FACE-DETECTION-ALGORITHMS-ARE-USED\" class=\"headerlink\" title=\"HOW FACE DETECTION ALGORITHMS ARE USED\"></a>HOW FACE DETECTION ALGORITHMS ARE USED</h2><p>Before we wrap up this guide, we wanted to give some examples of how face detection algorithms are applied in the real world. Some applications include photography, lip reading, marketing, and more.</p>\n<h3 id=\"FACIAL-MOTION-CAPTURE\"><a href=\"#FACIAL-MOTION-CAPTURE\" class=\"headerlink\" title=\"FACIAL MOTION CAPTURE\"></a>FACIAL MOTION CAPTURE</h3><p>With applications such as Snapchat, people‚Äôs faces can be altered in real-time with fun filters. Facial detection makes this possible, as its algorithms tell the applications that there is a face that can be traced and changed.</p>\n<h3 id=\"FACIAL-RECOGNITION\"><a href=\"#FACIAL-RECOGNITION\" class=\"headerlink\" title=\"FACIAL RECOGNITION\"></a>FACIAL RECOGNITION</h3><p><a href=\"https://recfaces.com/articles/what-is-facial-recognition-used-for\">Facial recognition</a> adds increased security to nearly every global industry. It seeks to identify a person and then authenticate their identity ‚Äì but for a person‚Äôs faceprint to be analyzed via facial recognition, the facial area to be assessed is determined by face detection.</p>\n<h3 id=\"PHOTOGRAPHY\"><a href=\"#PHOTOGRAPHY\" class=\"headerlink\" title=\"PHOTOGRAPHY\"></a>PHOTOGRAPHY</h3><p>Facial recognition can be used to ‚Äútag‚Äù people‚Äôs faces in photos across social media platforms, and facial detection forms the foundation of this application. Furthermore, facial detection technology can be used alongside tracking to focus on a person‚Äôs face while the photo is being taken.</p>\n<h3 id=\"MARKETING\"><a href=\"#MARKETING\" class=\"headerlink\" title=\"MARKETING\"></a>MARKETING</h3><p>Facial surveillance can help stores determine customers that have visited a few times and offer them perks or discounts ‚Äì thus fostering increased customer loyalty.</p>\n<h3 id=\"EMOTIONAL-INFERENCE\"><a href=\"#EMOTIONAL-INFERENCE\" class=\"headerlink\" title=\"EMOTIONAL INFERENCE\"></a>EMOTIONAL INFERENCE</h3><p>Emotion recognition applications are still in the works; when they are fully developed, AI might be able to ‚Äúread‚Äù nonverbal cues, gestures, body movements, and facial expressions to convey a person‚Äôs feelings.</p>\n<h3 id=\"LIP-READING\"><a href=\"#LIP-READING\" class=\"headerlink\" title=\"LIP READING\"></a>LIP READING</h3><p>The detection, modeling, and tracking of lips during videos can be used to generate automatic subtitles. Such an application can be found on YouTube, where some videos have the option to turn on subtitles, even if the creator has not provided any.</p>\n<h2 id=\"SUMMARY\"><a href=\"#SUMMARY\" class=\"headerlink\" title=\"SUMMARY\"></a>SUMMARY</h2><p>To sum up the key points of this guide:</p>\n<ul>\n<li>Face detection is AI-based computer technology that is used to extract and identify human faces from<br>digital images;</li>\n<li>Face detection algorithms can be feature-based, knowledge-based, template matching, appearance- based, or a combination of methods;</li>\n<li>Advantages of face detection include better security, easy integration, and automated identification;</li>\n<li>Disadvantages include huge storage requirements, vulnerable detection, and potential privacy issues.</li>\n</ul>\n<p>Face detection is the foundation of a huge number of facial applications ‚Äì we can see it in our day-to-day life. When we unlock our smartphone via face recognition, that would not be possible without face detection. The same goes for facial recognition surveillance systems, photo tagging, and Snapchat filters. There are many exciting applications in the works that we can thank face detection for!</p>\n<h2 id=\"Tutorial-Time\"><a href=\"#Tutorial-Time\" class=\"headerlink\" title=\"Tutorial Time\"></a>Tutorial Time</h2><p>Now we will see a small example of OpenCV and Python with its explanations, before we start we will need following software and if you are Linux base OS then you can skip installation process. Lets start.</p>\n<h3 id=\"Installation-on-Windows\"><a href=\"#Installation-on-Windows\" class=\"headerlink\" title=\"Installation on Windows\"></a>Installation on Windows</h3><p>Software we will be using</p>\n<ol>\n<li>PyCharm Community version</li>\n<li>Latest version of python</li>\n<li>And most import is your support. Lets start.</li>\n</ol>\n<h4 id=\"1-PyCharm-Community-version\"><a href=\"#1-PyCharm-Community-version\" class=\"headerlink\" title=\"1. PyCharm Community version\"></a>1. PyCharm Community version</h4><p>First open your favorite browser and paste this link in there <code>https://www.jetbrains.com/pycharm/download/</code> after that click on download under Community section.</p>\n<p><img src=\"/images/posts/pycharm.png\" alt=\"PyCharm\"></p>\n<p>After downloading it just open the installer you shall be granted with this screen</p>\n<p><img src=\"/images/posts/pycharm-community.png\" alt=\"PyCharm Community\"></p>\n<p>Click on next and complete installation process.</p>\n<h4 id=\"2-Python\"><a href=\"#2-Python\" class=\"headerlink\" title=\"2. Python\"></a>2. Python</h4><p>After completing installation of <code>PyCharm</code> now we will install Python, so same copy and past this link <code>https://www.python.org/downloads/</code> in browser and download installer</p>\n<p><img src=\"/images/posts/python-download.png\" alt=\"Python\"></p>\n<p>Now open the installer and start the installation process and make sure that you check all the options in <code>Optional Features</code> like this</p>\n<p><img src=\"/images/posts/python-optional-features.png\" alt=\"Python Optional Feature\"></p>\n<p>Now we are set for tutorial so open up your PyCharm.</p>\n<h3 id=\"Coding\"><a href=\"#Coding\" class=\"headerlink\" title=\"Coding\"></a>Coding</h3><p>First of all we will be opening PyCharm from start menu under JetBrains folder</p>\n<p><img src=\"/images/posts/jetbrains.png\" alt=\"JetBrains\"></p>\n<p>Create a new project named it OpenCV.</p>\n<p><img src=\"/images/posts/pycharm64_sdEaNyoXbp.png\" alt=\"pycharm64_sdEaNyoXbp\"></p>\n<p>After creating new project it will take few minutes to setup editor for us and after completing this will on your screen </p>\n<p><img src=\"/images/posts/pycharm64_c6nRLL7MiL.png\" alt=\"PyCharm Editor\"></p>\n<h4 id=\"Package-Installation\"><a href=\"#Package-Installation\" class=\"headerlink\" title=\"Package Installation\"></a>Package Installation</h4><p>Now clear everything in <code>main.py</code> and it should be empty after that we will be creating a text file called <code>requirement.txt</code> in your project folder using <code>cmd</code> for that you have to open <code>cmd</code>and navigate to you project folder like this</p>\n<p><img src=\"/images/posts/cmd_CnLDIMeHY8.png\" alt=\"CMD\"></p>\n<p>now type <code>notepad.exe requirement.txt</code> it will ask you for create a new file and click on yes after that paste bellow packages name there.</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">opencv-python</span><br><span class=\"line\">opencv-contrib-python</span><br><span class=\"line\">numpy</span><br><span class=\"line\">pillow</span><br></pre></td></tr></table></figure>\n\n<p>Save the file and close it now as we have saved the file we need to install all this packages by bellow command it will take a few minutes depending on your data transfer speed</p>\n<figure class=\"highlight cmd\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install -r requirement.txt</span><br></pre></td></tr></table></figure>\n\n<p>I have already installed it so it will give me this output</p>\n<p><img src=\"/images/posts/cmd_J3z721ij7x.png\" alt=\"Package installation\"></p>\n<h4 id=\"Video-detection\"><a href=\"#Video-detection\" class=\"headerlink\" title=\"Video detection\"></a>Video detection</h4><p>Close cmd and come back to your PyCharm, after we have installed all the required packages we will make a simple program for video capture so that we know that our video camera is working or not, but before we code in PyCharm we have to import all this packages we installed so follow me. First got to menu then File &gt; Settings and you will see this window.</p>\n<p><img src=\"/images/posts/pycharm64_PxPA5214bM.png\" alt=\"Project Settings\"></p>\n<p>Open <code>Project: OpenCV</code> and in that select <code>Python Interpreter</code> in that add all this packages</p>\n<p><img src=\"/images/posts/pycharm64_PxPA5214bM.png\" alt=\"Project Settings\"></p>\n<p>Now we will be coding a small program on video detection.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2 <span class=\"comment\">#importing opencv package</span></span><br><span class=\"line\">capture = cv2.VideoCapture(<span class=\"number\">0</span>) <span class=\"comment\"># we will create a variable name capture to capture webcam of our device which is &quot;0&quot; or else you can write ip address in &#x27;&#x27; of your webcam</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span>(<span class=\"literal\">True</span>):</span><br><span class=\"line\">    ret, frame = capture.read() <span class=\"comment\"># to read data from video capture variable</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">&quot;Video Feed&quot;</span>,frame) <span class=\"comment\"># to show live video camera feed</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> cv2.waitKey(<span class=\"number\">1</span>) &amp; <span class=\"number\">0xFF</span> == <span class=\"built_in\">ord</span>(<span class=\"string\">&#x27;q&#x27;</span>): <span class=\"comment\"># we have set waitKey at 0 means infinite or you can write any miliseconds and for ord(&#x27;q&#x27;) for quiting in live feed by pressing q on keyboard</span></span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">capture.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>\n\n<p>Now press <kbd>shift + F10</kbd> from keyboard or go-to menu Run &gt; Run ‚Äòmain‚Äô to run the program you may be able to see a new window with the name <code>Video Feed</code> try it yourself and you will be able to see your face. </p>\n<p><img src=\"/images/posts/vLylUVtgbB.png\" alt=\"Test image\">This is test image which I will be using it.</p>\n<h4 id=\"OpenCV-Cascade\"><a href=\"#OpenCV-Cascade\" class=\"headerlink\" title=\"OpenCV Cascade\"></a>OpenCV Cascade</h4><p>It means that our camera of our system is working properly now we need face detection cascades there are two ways of finding that files first is by downloading from <a href=\"/files/cascades.zip\">here</a> or by following commands open your cmd and type <code>python</code> or <code>py</code> after that type following commands</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"built_in\">print</span>(cv2.__file__)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/images/posts/WindowsTerminal_vDoEGwj6gk.png\" alt=\"CV2 Path\"></p>\n<p>Go to the highlighted path and in there you will be able to see all the files and in that file there will be a folder called data will be there</p>\n<p><img src=\"/images/posts/explorer_Ixdq0hGTPD.png\" alt=\"Data\"></p>\n<p>Copy that folder and past it in your project and rename from <code>data</code> to <code>cascade</code> like this.</p>\n<p><img src=\"/images/posts/explorer_sCfK1JWEKV.png\" alt=\"Cascade\"></p>\n<p>After doing we will be creating a new variable called <code>face_cascade</code> and in that variable we will use OpenCV, paste this code in your main.py file</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2 <span class=\"comment\">#add bellow this line</span></span><br><span class=\"line\">face_cascade = cv2.CascadeClassifier(<span class=\"string\">&#x27;cascades/haarcascade_frontalface_alt.xml&#x27;</span>) </span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Using-Face-Classifier\"><a href=\"#Using-Face-Classifier\" class=\"headerlink\" title=\"Using Face Classifier\"></a>Using Face Classifier</h4><p>Now we will be converting our colored BGR color to Gray color so that our cascade can understand the image properly, mostly face detection works in gray scale so we will be converting our colored frame to gray scale. For that you have to create a new variable called gray under <code>ret, frame = capture.read()</code>. Remember OpenCV uses BGR method while for other color code it is RGB you must be familiar with RGB so you will understand BGR. Now we will add this line into our code </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ret, frame = capture.read() <span class=\"comment\"># add bellow this line</span></span><br><span class=\"line\">gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) <span class=\"comment\"># to convert BGR image to grayscale image</span></span><br></pre></td></tr></table></figure>\n\n<p> and don‚Äôt worry if your not able to understand the code I will be giving you project like so that you can download it and run it on your own. We will now detect faces in webcam, photo frame or video. For that we will be using gray scale which we have converted from BGR ti GRAY so for that we need <code>detectMultiScale</code> function for scale factor and minimum neighbors detection.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) <span class=\"comment\">#add bellow this</span></span><br><span class=\"line\">faces = face_cascade.detectMultiScale(gray, scaleFactor=<span class=\"number\">1.5</span>, minNeighbors=<span class=\"number\">5</span>) <span class=\"comment\"># you can play with the numbers as much as you want</span></span><br></pre></td></tr></table></figure>\n\n<p>now we will pe finding our face in frame by finding position and checking whether the face is present or not for that we will be using width, height, x direction, y direction of the video feed.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">faces = face_cascade.detectMultiScale(gray, scaleFactor=<span class=\"number\">1.5</span>, minNeighbors=<span class=\"number\">5</span>)  <span class=\"comment\"># add bellow this line</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (x, y, w, h) <span class=\"keyword\">in</span> faces:</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(x,y,w,h) <span class=\"comment\"># print coordinates of your face</span></span><br></pre></td></tr></table></figure>\n\n<p>This command will show you the coordinates of your face in the frame so that we can identify that someone is present here.</p>\n<p><img src=\"/images/posts/9GZxLCVtAp.png\" alt=\"Face Coordinate&#39;s\"></p>\n<p>Now we will be drawing a square around our face so that we can clearly identify it for that we will be will be using gray scale image. Now we will make a region of interest or ROI using gray scale image to determine its width and height</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> (x, y, w, h) <span class=\"keyword\">in</span> faces:</span><br><span class=\"line\">     <span class=\"built_in\">print</span>(x,y,w,h) <span class=\"comment\"># print bellow this line</span></span><br><span class=\"line\">     roi_gray = gray[y:y + h, x:x + h] <span class=\"comment\"># regoin of interest of gray scale image</span></span><br><span class=\"line\">     roi_color = frame[y:y + h, x:x + w] <span class=\"comment\"># regoin of interest of colored image</span></span><br></pre></td></tr></table></figure>\n\n<p>so now as we have found our region of interest we will check that whether it is working properly or not so we will capture our face by making a PNG fine</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roi_color = frame[y:y + h, x:x + w] <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">  \timg_item = <span class=\"string\">&quot;my-image.png&quot;</span> <span class=\"comment\"># creating a variable name img_item</span></span><br><span class=\"line\">  \tcv2.imwrite(img_item, roi_color) <span class=\"comment\"># to create an image file where we can see our face only</span></span><br></pre></td></tr></table></figure>\n\n<p>What this above line will do is that it will create an PNG file with the name <code>my-image.png</code> in your project folder so that we can understand that which portion of our face is been captured.</p>\n<p> <img src=\"/images/posts/ATItkXEuFa.png\" alt=\"my-image.png\"></p>\n<p>After detecting our face and saving it in a PNG file what we will do is that we will create a border and track our live feed cam and see it more clearly</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cv2.imwrite(img_item, roi_color) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">color = (<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">255</span>) <span class=\"comment\"># BGR format you can choose whatever you want go to this site to choose color https://wamingo.net/rgbbgr/</span></span><br><span class=\"line\">   stroke = <span class=\"number\">2</span></span><br><span class=\"line\">   end_cord_x = x + w</span><br><span class=\"line\">   end_cord_y = y + h</span><br><span class=\"line\">   cv2.rectangle(frame,(x, y), (end_cord_x, end_cord_y), color, stroke)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/images/posts/bzUl6UbhVI.png\" alt=\"Drawing rectangle on face\"></p>\n<p>Until now what we have done is that we have just detecting our face using <code>Cascades</code> but as we have successfully done it so now we will be creating recognizer to recognize who is that person is for that we will be creating an algorithm. So now we will be creating new python file <code>train-faces.py</code> so that we will be writing all the algorithm in it to train our facial recognition system. After creating <code>train-faces.py</code> file we will create a folder of name <code>images</code> where we will be adding all images in it to train our trainer. Open train-faces.py and type the following code:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os <span class=\"comment\"># to detect which kind of operating system we are been using example: Windows, Linux, Debian, Mac, etc.</span></span><br><span class=\"line\">BASE_DIR = os.path.dirname(os.path.abspath(__file__)) <span class=\"comment\"># to automatical find out the path of our project</span></span><br></pre></td></tr></table></figure>\n\n<p>What we have done is that we told the system to find the path of our project automatically and also to detect os also and after detecting our project folder we will be adding our images directory so that we will be able to find all images at one place.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BASE_DIR = os.path.dirname(os.path.abspath(__file__)) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">image_dir = os.path.join(BASE_DIR, <span class=\"string\">&quot;images&quot;</span>) <span class=\"comment\"># this will add images at the end of our base dir example: C:\\User\\Admin\\Desktop\\facedetection\\images\\</span></span><br></pre></td></tr></table></figure>\n\n<p>As our system or file has detected the path we will check all the images which are present in it.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">image_dir = os.path.join(BASE_DIR, <span class=\"string\">&quot;images&quot;</span>) <span class=\"comment\"># add bellow this line</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> root, dirs, files <span class=\"keyword\">in</span> os.walk(image_dir): <span class=\"comment\"># this will detect our image path</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> files: </span><br><span class=\"line\">        <span class=\"keyword\">if</span> file.endswith(<span class=\"string\">&quot;png&quot;</span>) <span class=\"keyword\">or</span> file.endswith(<span class=\"string\">&quot;jpg&quot;</span>): <span class=\"comment\"># this is use to check whether there are png file or jpg files</span></span><br><span class=\"line\">            path = os.path.join(root, file) <span class=\"comment\"># this will join our project director and images folder path</span></span><br><span class=\"line\">            <span class=\"built_in\">print</span>(path) <span class=\"comment\"># to check all the apth of images</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/images/posts/pycharm64_QFG764uyci.png\" alt=\"Image path\"></p>\n<p>Now what we will do is that we will be giving labels to our directories which are present in images folder </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">      path = os.path.join(root, file) <span class=\"comment\"># add bellow this line</span></span><br><span class=\"line\">label = os.path.basename(root) <span class=\"comment\"># to give the label of our image folder</span></span><br><span class=\"line\">  \t<span class=\"built_in\">print</span>(label, path) <span class=\"comment\"># add label in old print function</span></span><br></pre></td></tr></table></figure>\n\n<p>So when we will run the code now we will be able to see path as well as label. So now we will be creating empty list.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">image_dir = os.path.join(BASE_DIR, <span class=\"string\">&quot;images&quot;</span>) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">y_labels = []</span><br><span class=\"line\">x_train = []</span><br></pre></td></tr></table></figure>\n\n<p>Training images using <code>NumPy</code> array also we will be using <code>PIL</code> python library to grab pill of image</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2 <span class=\"comment\">#add bellow this</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br></pre></td></tr></table></figure>\n\n<p>After importing Image from PIL library we will be converting image into gray</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  \t<span class=\"built_in\">print</span>(label, path) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">pil_image = Image.<span class=\"built_in\">open</span>(path).convert(<span class=\"string\">&quot;L&quot;</span>) <span class=\"comment\"># to convert colored image to gray scale</span></span><br></pre></td></tr></table></figure>\n\n<p>Now we will be using NumPy array to train our images</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pil_image = Image.open(path).convert(&quot;L&quot;) # add bellow this line</span><br><span class=\"line\">image_array = np.array(pil_image, &quot;uint8&quot;)</span><br><span class=\"line\">print(image_array) # to check images array</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/images/posts/pycharm64_D0vgyFuYoF.png\" alt=\"Image Array\"></p>\n<p>We will check ROI of images so that we can train our trainer for that we need to <code>import cv2</code> into our <code>train-faces.py</code> using our Cascades</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2 </span><br><span class=\"line\">BASE_DIR = os.path.dirname(os.path.abspath(__file__)) <span class=\"comment\"># to automatical find out the path of our project</span></span><br><span class=\"line\"></span><br><span class=\"line\">image_dir = os.path.join(BASE_DIR, <span class=\"string\">&quot;images&quot;</span>) <span class=\"comment\"># this will add images at the end of our base dir example: C:\\User\\Admin\\Desktop\\facedetection\\images\\</span></span><br><span class=\"line\">face_cascade = cv2.CascadeClassifier(<span class=\"string\">&#x27;cascades/haarcascade_frontalface_alt2.xml&#x27;</span>) <span class=\"comment\"># add this line</span></span><br></pre></td></tr></table></figure>\n\n<p>After importing OpenCV and Cascades we will be detecting faces using <code>detectMultiScale</code>.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">      <span class=\"built_in\">print</span>(image_array) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">faces = face_cascade.detectMultiScale(image_array, scaleFactor=<span class=\"number\">1.5</span>, minNeighbors=<span class=\"number\">5</span>)</span><br><span class=\"line\">      <span class=\"keyword\">for</span> (x, y, w, h) <span class=\"keyword\">in</span> faces:</span><br><span class=\"line\">          roi = image_array[y:y + h, x:x + w]</span><br><span class=\"line\">          x_train.append(roi)</span><br></pre></td></tr></table></figure>\n\n<p>We will be giving labels so that it would be easy to understand it properly, also not that it would be easy to see who is the person in the video feed or photo frame for that we will be creating a variable.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">face_cascade = cv2.CascadeClassifier(<span class=\"string\">&#x27;cascades/haarcascade_frontalface_alt2.xml&#x27;</span>) <span class=\"comment\"># add bellow this line</span></span><br><span class=\"line\">current_id = <span class=\"number\">0</span> <span class=\"comment\"># creating an id starting with 0</span></span><br><span class=\"line\">label_ids = &#123;&#125; <span class=\"comment\"># to create and empty directory</span></span><br><span class=\"line\"><span class=\"comment\"># Now come down to this line </span></span><br><span class=\"line\">        \t<span class=\"built_in\">print</span>(label, path) <span class=\"comment\"># ad bellow this</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> label <span class=\"keyword\">in</span> label_ids: <span class=\"comment\"># it will check whether the labels are there or not</span></span><br><span class=\"line\">                label_ids[label] = current_id</span><br><span class=\"line\">                current_id += <span class=\"number\">1</span></span><br><span class=\"line\">            id_ = label_ids[label]</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(label_ids) <span class=\"comment\"># to print label ids</span></span><br><span class=\"line\"><span class=\"comment\"># Now come down to this line </span></span><br><span class=\"line\">\t\t\t\tx_train.append(roi) <span class=\"comment\"># add bellow this line</span></span><br><span class=\"line\">                y_labels.append(id_)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_labels)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_train)</span><br></pre></td></tr></table></figure>\n\n<p>What we have done is that we have created labels ids for each and every image we have so after doing that we will saving all thoes lables so that it would be easy for our program to recognize it for that we need pickle so I assume that you know who to import any library so import pickle. Now go to the bottom of you train-faces.py file and paste bellow code but before pasting this code make sure to add <code>#</code> infront of <code>print</code> function.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&quot;labels.pickle&quot;</span>, <span class=\"string\">&quot;wb&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    pickle.dump(label_ids, f)</span><br></pre></td></tr></table></figure>\n\n<p>After this we will train our OpenCV recognizer for each an every images so that it can recognize it propely so for that we will create a variable call recognizer.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">face_cascade = cv2.CascadeClassifier(<span class=\"string\">&#x27;cascades/haarcascade_frontalface_alt2.xml&#x27;</span>) <span class=\"comment\"># add bellow this line</span></span><br><span class=\"line\">recognizer = cv2.face.LBPHFaceRecognizer_create() <span class=\"comment\">#creating our face recognizer</span></span><br></pre></td></tr></table></figure>\n\n<p>Successful creation of our recognizer we will be needing numpy array to save all those array in a single file and remember one thing the more numbers of photo will take more time to write it also it deppends on speed of your devices also.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&quot;labels.pickle&quot;</span>, <span class=\"string\">&quot;wb&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    pickle.dump(label_ids, f) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">recognizer.train(x_train, np.array(y_labels)) <span class=\"comment\"># using numpy array we will be training our recognizer</span></span><br><span class=\"line\">recognizer.save(<span class=\"string\">&quot;trainer.yml&quot;</span>) <span class=\"comment\"># and from above training we will be saving it in a single file called trainner.yml</span></span><br></pre></td></tr></table></figure>\n\n\n<p>As we have completed our <code>train-faces.py</code> we will run it and train our project so that we can recognize our faces, so now go to your cmd and <code>type py tain-faces.py</code> and wait until you get this message</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Process finished with exit code 0</span><br></pre></td></tr></table></figure>\n\n<p>After you see this message it means that our trainer has been successfully trained so main.py is been left to update for final run. Now open your main.py file and past this line</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">face_cascade = cv2.CascadeClassifier(<span class=\"string\">&#x27;cascades/haarcascade_frontalface_alt2.xml&#x27;</span>) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">recognizer = cv2.face.LBPHFaceRecognizer_create() <span class=\"comment\">#creating our face recognizer</span></span><br><span class=\"line\">recongnizer.read(<span class=\"string\">&quot;trainer.yml&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&quot;labels.pickle&quot;</span>, <span class=\"string\">&quot;rb&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    og_labels = pickle.load(f)</span><br></pre></td></tr></table></figure>\n\n<p>What we did is imported <code>trainer.yml</code> so that we can read all the data we have been trained data. After that we will be import all the the tags and ids we have created.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">roi_color = img[y:y + h, x:x + w] <span class=\"comment\"># add bellow this line</span></span><br><span class=\"line\">id_, conf = recognizer.predict(roi_gray)</span><br><span class=\"line\">  <span class=\"keyword\">if</span> conf&gt;= <span class=\"number\">45</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(id_)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Loading-Label-Names-from-Pickle\"><a href=\"#Loading-Label-Names-from-Pickle\" class=\"headerlink\" title=\"Loading Label Names from Pickle\"></a>Loading Label Names from Pickle</h4><p>Now we will labels from <code>labels.pickle</code> so that we can identify labels, so what we will do is fetch all the labels from that file.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">recognizer.read(&quot;trainer.yml&quot;) # add bellow this</span><br><span class=\"line\"></span><br><span class=\"line\">labels = &#123;&quot;person_name&quot;: 1&#125; # display person name</span><br></pre></td></tr></table></figure>\n\n<p>What we did is we will display person name so to do that we are going to add this line to display it</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">og_labels = pickle.load(f) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">labels = &#123;v:k <span class=\"keyword\">for</span> k,v <span class=\"keyword\">in</span> labels.items()&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Now we will print ids</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(id_) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">    </span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Put-Text-on-your-face\"><a href=\"#Put-Text-on-your-face\" class=\"headerlink\" title=\"Put Text on your face\"></a>Put Text on your face</h4><p>We will put text on our webcam face recognition so that we can identify who is that person is for that we will be using <code>putText</code> function.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> conf &gt;= <span class=\"number\">45</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(id_)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(labels[id_]) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">    font = cv2.FONT_HERSHEY_SIMPLEX</span><br><span class=\"line\">    name = labels[id_]</span><br><span class=\"line\">    color = (<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">255</span>) <span class=\"comment\"># BGR choose any color you like</span></span><br></pre></td></tr></table></figure>\n\n<p>We will resize little bit so that it reads perfectly in <code>train-faces.py</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">         pil_image = Image.<span class=\"built_in\">open</span>(path).convert(<span class=\"string\">&quot;L&quot;</span>) <span class=\"comment\"># add bellow this</span></span><br><span class=\"line\">size = (<span class=\"number\">500</span>,<span class=\"number\">500</span>)</span><br><span class=\"line\">         final_image = pil_image.rezise(size, Image.ANTIALIAS)</span><br></pre></td></tr></table></figure>\n\n<p>After saving both the files run your main.py file and check the output of it.</p>\n<h4 id=\"Complete-Code\"><a href=\"#Complete-Code\" class=\"headerlink\" title=\"Complete Code\"></a>Complete Code</h4><p><strong>requirement.txt</strong></p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">opencv-python</span><br><span class=\"line\">opencv-contrib-python</span><br><span class=\"line\">numpy</span><br><span class=\"line\">pillow</span><br></pre></td></tr></table></figure>\n\n<p><strong>main.py</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2 </span><br><span class=\"line\"><span class=\"keyword\">import</span> pickle</span><br><span class=\"line\"><span class=\"comment\"># url = &#x27;&#x27; # add your remote ip of webcam example &#x27;http://192.168.0.1/video&#x27; or &#x27;http://192.168.0.1&#x27; depending on your ip even you can use security camera ip also</span></span><br><span class=\"line\">face_cascade = cv2.CascadeClassifier(<span class=\"string\">&#x27;cascades/haarcascade_frontalface_alt2.xml&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">recognizer = cv2.face.LBPHFaceRecognizer_create()</span><br><span class=\"line\">recognizer.read(<span class=\"string\">&quot;trainer.yml&quot;</span>)</span><br><span class=\"line\">labels = &#123;<span class=\"string\">&quot;person_name&quot;</span>: <span class=\"number\">1</span>&#125;</span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&quot;labels.pickle&quot;</span>,<span class=\"string\">&quot;rb&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    og_labels = pickle.load(f)</span><br><span class=\"line\">    labels = &#123;v:k <span class=\"keyword\">for</span> k,v <span class=\"keyword\">in</span> og_labels.items()&#125;</span><br><span class=\"line\">cap = cv2.VideoCapture(<span class=\"number\">0</span>) <span class=\"comment\"># comment this if your using ip camera</span></span><br><span class=\"line\"><span class=\"comment\"># cap = cv2.VideoCapture(url) # uncomment this line to use remote camera url</span></span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">3</span>,<span class=\"number\">512</span>)</span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">4</span>,<span class=\"number\">512</span>)</span><br><span class=\"line\">cap.<span class=\"built_in\">set</span>(<span class=\"number\">10</span>,<span class=\"number\">150</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># Capture frame-by-frame</span></span><br><span class=\"line\">    ret, frame = cap.read()</span><br><span class=\"line\">    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">    faces = face_cascade.detectMultiScale(gray, scaleFactor=<span class=\"number\">1.5</span>, minNeighbors=<span class=\"number\">5</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (x, y, w, h) <span class=\"keyword\">in</span> faces:</span><br><span class=\"line\">        <span class=\"comment\"># print(x,y,w,h)</span></span><br><span class=\"line\">        roi_gray = gray[y:y+h, x:x+w]</span><br><span class=\"line\">        roi_color = frame[y:y+h, x:x+w]</span><br><span class=\"line\">        id_, conf = recognizer.predict(roi_gray)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> conf&gt;=<span class=\"number\">45</span>: <span class=\"comment\"># and conf&lt;=85:</span></span><br><span class=\"line\">            <span class=\"comment\"># print(id_)</span></span><br><span class=\"line\">            <span class=\"comment\"># print(labels[id_])</span></span><br><span class=\"line\">            font = cv2.FONT_HERSHEY_SIMPLEX</span><br><span class=\"line\">            name = labels[id_]</span><br><span class=\"line\">            color = (<span class=\"number\">0</span>,<span class=\"number\">255</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\">            stroke = <span class=\"number\">2</span></span><br><span class=\"line\">            cv2.putText(frame, name, (x,y), font, <span class=\"number\">1</span>, color, stroke, cv2.LINE_AA)</span><br><span class=\"line\"></span><br><span class=\"line\">        img_item = <span class=\"string\">&quot;test.png&quot;</span></span><br><span class=\"line\">        cv2.imwrite(img_item, roi_color)</span><br><span class=\"line\">        color = (<span class=\"number\">0</span>,<span class=\"number\">255</span>,<span class=\"number\">0</span>) <span class=\"comment\"># BGR</span></span><br><span class=\"line\">        stroke = <span class=\"number\">2</span></span><br><span class=\"line\">        end_cord_x = x + w</span><br><span class=\"line\">        end_cord_y = y + h</span><br><span class=\"line\">        cv2.rectangle(frame, (x, y), (end_cord_x, end_cord_y), color, stroke)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Display the resulting frame</span></span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">&#x27;Frame&#x27;</span>,frame)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> cv2.waitKey(<span class=\"number\">1</span>) &amp; <span class=\"number\">0xFF</span> == <span class=\"built_in\">ord</span>(<span class=\"string\">&#x27;q&#x27;</span>):</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\"></span><br><span class=\"line\">cap.release()</span><br><span class=\"line\">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>\n\n<p><strong>train-faces.py</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pickle</span><br><span class=\"line\"></span><br><span class=\"line\">BASE_DIR = os.path.dirname(os.path.abspath(__file__))</span><br><span class=\"line\">image_dir = os.path.join(BASE_DIR, <span class=\"string\">&quot;images&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">face_cascade = cv2.CascadeClassifier(<span class=\"string\">&#x27;cascades/haarcascade_frontalface_default.xml&#x27;</span>)</span><br><span class=\"line\">recognizer = cv2.face.LBPHFaceRecognizer_create()</span><br><span class=\"line\"></span><br><span class=\"line\">current_id = <span class=\"number\">0</span></span><br><span class=\"line\">label_ids = &#123;&#125;</span><br><span class=\"line\">y_labels = []</span><br><span class=\"line\">x_train = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> root, dirs, files <span class=\"keyword\">in</span> os.walk(image_dir):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> files:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> file.endswith(<span class=\"string\">&quot;png&quot;</span>) <span class=\"keyword\">or</span> file.endswith(<span class=\"string\">&quot;jpg&quot;</span>):</span><br><span class=\"line\">            path = os.path.join(root, file)</span><br><span class=\"line\">            label = os.path.basename(root).replace(<span class=\"string\">&quot; &quot;</span>, <span class=\"string\">&quot; &quot;</span>) <span class=\"comment\">#.upper()</span></span><br><span class=\"line\">            <span class=\"comment\"># print(label,path)</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> label <span class=\"keyword\">in</span> label_ids:</span><br><span class=\"line\">                label_ids[label] = current_id</span><br><span class=\"line\">                current_id += <span class=\"number\">1</span></span><br><span class=\"line\">            id_ = label_ids[label]</span><br><span class=\"line\">            <span class=\"comment\"># print(label_ids )</span></span><br><span class=\"line\">            <span class=\"comment\"># y_labels.append(label)</span></span><br><span class=\"line\">            <span class=\"comment\"># x_train.append(path)</span></span><br><span class=\"line\">            pil_image = Image.<span class=\"built_in\">open</span>(path).convert(<span class=\"string\">&quot;L&quot;</span>)</span><br><span class=\"line\">            size = (<span class=\"number\">512</span>,<span class=\"number\">512</span>)</span><br><span class=\"line\">            final_image = pil_image.resize(size, Image.ANTIALIAS)</span><br><span class=\"line\">            image_array = np.array(pil_image, <span class=\"string\">&quot;uint8&quot;</span>)</span><br><span class=\"line\">            <span class=\"comment\"># print(image_array)</span></span><br><span class=\"line\">            faces = face_cascade.detectMultiScale(image_array, scaleFactor=<span class=\"number\">1.5</span>, minNeighbors=<span class=\"number\">5</span>)</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (x,y,w,h) <span class=\"keyword\">in</span> faces:</span><br><span class=\"line\">                roi = image_array[y:y+h, x:x+w]</span><br><span class=\"line\">                x_train.append(roi)</span><br><span class=\"line\">                y_labels.append(id_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print(y_labels)</span></span><br><span class=\"line\"><span class=\"comment\"># print(x_train)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&quot;labels.pickle&quot;</span>,<span class=\"string\">&quot;wb&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    pickle.dump(label_ids, f)</span><br><span class=\"line\"></span><br><span class=\"line\">recognizer.train(x_train, np.array(y_labels))</span><br><span class=\"line\">recognizer.save(<span class=\"string\">&quot;trainer.yml&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Source-Code\"><a href=\"#Source-Code\" class=\"headerlink\" title=\"Source Code\"></a>Source Code</h4><p>Here is the source code <a href=\"https://github.com/mrfoxie/OpenCV-Facial-Recognition\">OpenCV Facial Recognition</a> on GitHub if you have any issues then you can ask there.</p>\n","text":" What is Face Detection?Face detection is AI-based computer technology that is u...","link":"","photos":[],"count_time":{"symbolsCount":"33k","symbolsTime":"30 mins."},"categories":[{"name":"Industrial automation","slug":"Industrial-automation","count":4,"path":"api/categories/Industrial-automation.json"},{"name":"Simulation","slug":"Industrial-automation/Simulation","count":1,"path":"api/categories/Industrial-automation/Simulation.json"},{"name":"technology","slug":"Industrial-automation/Simulation/technology","count":1,"path":"api/categories/Industrial-automation/Simulation/technology.json"},{"name":"Windows","slug":"Industrial-automation/Simulation/technology/Windows","count":1,"path":"api/categories/Industrial-automation/Simulation/technology/Windows.json"}],"tags":[{"name":"technology","slug":"technology","count":15,"path":"api/tags/technology.json"},{"name":"industrial automation","slug":"industrial-automation","count":6,"path":"api/tags/industrial-automation.json"},{"name":"ubuntu","slug":"ubuntu","count":4,"path":"api/tags/ubuntu.json"},{"name":"information","slug":"information","count":2,"path":"api/tags/information.json"},{"name":"robotics","slug":"robotics","count":3,"path":"api/tags/robotics.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#What-is-Face-Detection\"><span class=\"toc-text\">What is Face Detection?</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#HOW-DOES-FACE-DETECTION-WORK\"><span class=\"toc-text\">HOW DOES FACE DETECTION WORK?</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#FACE-DETECTION-METHODS\"><span class=\"toc-text\">FACE DETECTION METHODS</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Feature-Based-Method\"><span class=\"toc-text\">Feature-Based Method</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Knowledge-Based-Method\"><span class=\"toc-text\">Knowledge-Based Method</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Template-Matching-Method\"><span class=\"toc-text\">Template Matching Method</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Appearance-Based-Method\"><span class=\"toc-text\">Appearance-Based Method</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#FACE-DETECTION-TECHNIQUES\"><span class=\"toc-text\">FACE DETECTION TECHNIQUES</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#WHAT-ARE-THE-CHALLENGES-IN-FACE-DETECTION\"><span class=\"toc-text\">WHAT ARE THE CHALLENGES IN FACE DETECTION?</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#HOW-DOES-FACE-DETECTION-WORK-WITH-DEEP-LEARNING\"><span class=\"toc-text\">HOW DOES FACE DETECTION WORK WITH DEEP LEARNING?</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#WHY-IS-FACE-DETECTION-IMPORTANT-TODAY\"><span class=\"toc-text\">WHY IS FACE DETECTION IMPORTANT TODAY?</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#FACE-DETECTION-VS-FACE-RECOGNITION-WHAT%E2%80%99S-THE-DIFFERENCE\"><span class=\"toc-text\">FACE DETECTION VS. FACE RECOGNITION: WHAT‚ÄôS THE DIFFERENCE?</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ADVANTAGES-AND-DISADVANTAGES-OF-FACE-DETECTION-SYSTEMS\"><span class=\"toc-text\">ADVANTAGES AND DISADVANTAGES OF FACE DETECTION SYSTEMS</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#ADVANTAGES-OF-FACE-DETECTION\"><span class=\"toc-text\">ADVANTAGES OF FACE DETECTION</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#DISADVANTAGES-OF-FACE-DETECTION\"><span class=\"toc-text\">DISADVANTAGES OF FACE DETECTION</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#PROS-AND-CONS-TABLE-SUMMARY\"><span class=\"toc-text\">PROS AND CONS TABLE SUMMARY</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#HOW-FACE-DETECTION-ALGORITHMS-ARE-USED\"><span class=\"toc-text\">HOW FACE DETECTION ALGORITHMS ARE USED</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#FACIAL-MOTION-CAPTURE\"><span class=\"toc-text\">FACIAL MOTION CAPTURE</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#FACIAL-RECOGNITION\"><span class=\"toc-text\">FACIAL RECOGNITION</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#PHOTOGRAPHY\"><span class=\"toc-text\">PHOTOGRAPHY</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#MARKETING\"><span class=\"toc-text\">MARKETING</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#EMOTIONAL-INFERENCE\"><span class=\"toc-text\">EMOTIONAL INFERENCE</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#LIP-READING\"><span class=\"toc-text\">LIP READING</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#SUMMARY\"><span class=\"toc-text\">SUMMARY</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Tutorial-Time\"><span class=\"toc-text\">Tutorial Time</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Installation-on-Windows\"><span class=\"toc-text\">Installation on Windows</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#1-PyCharm-Community-version\"><span class=\"toc-text\">1. PyCharm Community version</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2-Python\"><span class=\"toc-text\">2. Python</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Coding\"><span class=\"toc-text\">Coding</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Package-Installation\"><span class=\"toc-text\">Package Installation</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Video-detection\"><span class=\"toc-text\">Video detection</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#OpenCV-Cascade\"><span class=\"toc-text\">OpenCV Cascade</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Using-Face-Classifier\"><span class=\"toc-text\">Using Face Classifier</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Loading-Label-Names-from-Pickle\"><span class=\"toc-text\">Loading Label Names from Pickle</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Put-Text-on-your-face\"><span class=\"toc-text\">Put Text on your face</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Complete-Code\"><span class=\"toc-text\">Complete Code</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Source-Code\"><span class=\"toc-text\">Source Code</span></a></li></ol></li></ol></li></ol>","author":{"name":"Mistry Siddh","slug":"blog-author","avatar":"https://www.mistrysiddh.com/images/whoami/avatar.png","link":"https://www.mistrysiddh.com/","description":"Believe in the Person who Believes in you.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"Announcement","uid":"aa4aef35646395a3769294d84bc89509","slug":"announcement","date":"2021-07-07T05:52:36.000Z","updated":"2025-01-10T03:40:13.644Z","comments":true,"path":"api/articles/announcement.json","keywords":null,"cover":"/images/posts/play-store.jpg","text":"Application LaunchedI‚Äôm happy to announce that play store has accepted my applic...","link":"","photos":[],"count_time":{"symbolsCount":233,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"Mistry Siddh","slug":"blog-author","avatar":"https://www.mistrysiddh.com/images/whoami/avatar.png","link":"https://www.mistrysiddh.com/","description":"Believe in the Person who Believes in you.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"pinned":false},"next_post":{"title":"WSL Graphics","uid":"3ace24ac28637c8144f86387ed671f15","slug":"WSLG","date":"2021-06-19T09:59:27.000Z","updated":"2025-01-10T03:40:13.644Z","comments":true,"path":"api/articles/WSLG.json","keywords":null,"cover":"images/posts/WSLg_IntegratedDesktop.png","text":"RecapsIn previous post we have seen how to install Windows Subsystem Linux in yo...","link":"","photos":[],"count_time":{"symbolsCount":"6.3k","symbolsTime":"6 mins."},"categories":[{"name":"technology","slug":"technology","count":3,"path":"api/categories/technology.json"}],"tags":[{"name":"technology","slug":"technology","count":15,"path":"api/tags/technology.json"},{"name":"Linux","slug":"Linux","count":8,"path":"api/tags/Linux.json"},{"name":"ubuntu","slug":"ubuntu","count":4,"path":"api/tags/ubuntu.json"},{"name":"wsl","slug":"wsl","count":2,"path":"api/tags/wsl.json"},{"name":"wsl2","slug":"wsl2","count":2,"path":"api/tags/wsl2.json"}],"author":{"name":"Mistry Siddh","slug":"blog-author","avatar":"https://www.mistrysiddh.com/images/whoami/avatar.png","link":"https://www.mistrysiddh.com/","description":"Believe in the Person who Believes in you.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}